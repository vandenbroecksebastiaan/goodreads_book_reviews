Epoch:   0%|                                                                                                                     | 0/1 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 26, in <module>
    main()
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 22, in main
    train(model, train_loader, eval_loader)
  File "/home/sebastiaan/fun/goodreads_book_reviews/train.py", line 25, in train
    train_output = model(input_id, attention_mask)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/fun/goodreads_book_reviews/model.py", line 18, in forward
    distilbert_output = self.pretrained_model(input_id, attention_mask)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 579, in forward
    return self.transformer(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 355, in forward
    layer_outputs = layer_module(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 308, in forward
    ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 249, in forward
    return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py", line 249, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 254, in ff_chunk
    x = self.lin2(x)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 11.75 GiB total capacity; 10.32 GiB already allocated; 16.12 MiB free; 10.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 26, in <module>
    main()
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 22, in main
    train(model, train_loader, eval_loader)
  File "/home/sebastiaan/fun/goodreads_book_reviews/train.py", line 25, in train
    train_output = model(input_id, attention_mask)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/fun/goodreads_book_reviews/model.py", line 18, in forward
    distilbert_output = self.pretrained_model(input_id, attention_mask)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 579, in forward
    return self.transformer(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 355, in forward
    layer_outputs = layer_module(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 308, in forward
    ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 249, in forward
    return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py", line 249, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 254, in ff_chunk
    x = self.lin2(x)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 11.75 GiB total capacity; 10.32 GiB already allocated; 16.12 MiB free; 10.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
0 0 tensor(1.9051, device='cuda:0', grad_fn=<NllLossBackward0>) tensor([1, 3, 2, 4, 1, 3, 3, 3, 4, 4], device='cuda:0')