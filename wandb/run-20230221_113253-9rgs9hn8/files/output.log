Epoch:   0%|                                                                                                                   | 0/1 [00:00<?, ?it/s]




Traceback (most recent call last):
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 26, in <module>
    main()
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 22, in main
    train(model, train_loader, eval_loader)
  File "/home/sebastiaan/fun/goodreads_book_reviews/train.py", line 31, in train
    for idx, data in tqdm(enumerate(train_loader), leave=False, total=tot):
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 295, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/sebastiaan/fun/goodreads_book_reviews/data.py", line 90, in __getitem__
    x_data = self.tokenizer(self.review_text[index],
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2523, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2629, in _call_one
    return self.encode_plus(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2702, in encode_plus
    return self._encode_plus(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils.py", line 652, in _encode_plus
    return self.prepare_for_model(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3181, in prepare_for_model
    encoded_inputs = self.pad(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2946, in pad
    if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):
  File "/usr/lib/python3.10/abc.py", line 119, in __instancecheck__
    return _abc_instancecheck(cls, instance)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 26, in <module>
    main()
  File "/home/sebastiaan/fun/goodreads_book_reviews/main.py", line 22, in main
    train(model, train_loader, eval_loader)
  File "/home/sebastiaan/fun/goodreads_book_reviews/train.py", line 31, in train
    for idx, data in tqdm(enumerate(train_loader), leave=False, total=tot):
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 295, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/sebastiaan/fun/goodreads_book_reviews/data.py", line 90, in __getitem__
    x_data = self.tokenizer(self.review_text[index],
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2523, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2629, in _call_one
    return self.encode_plus(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2702, in encode_plus
    return self._encode_plus(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils.py", line 652, in _encode_plus
    return self.prepare_for_model(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3181, in prepare_for_model
    encoded_inputs = self.pad(
  File "/home/sebastiaan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2946, in pad
    if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):
  File "/usr/lib/python3.10/abc.py", line 119, in __instancecheck__
    return _abc_instancecheck(cls, instance)
KeyboardInterrupt